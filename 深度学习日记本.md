# 深度学习00

## 正则化

正则化 和 正则表达式 没有任何联系！！！

正则化：用各种方法去规范模型参数的方法。DropOut也是一种正则化。

花书中对正则化的定义：凡是可以减少泛化误差 而不是减少训练误差的方法，都可以称作正则化方法。（简单来说：凡是能减少过拟合的方法都是正则化方法）

L2范数：欧式距离，图像是一个圆

L1范数：曼哈顿距离，图像是一个旋转45°的正方形

注意：在两组计算中，即使得到的损失函数的值一样，但是w和b的取值很可能不相同，主要取决于w和b的初始值设置。所以为了不让这两个参数太大，我们就需要 把这两个参数的取值范围放到一个框框里。

## SVM支持向量机Support Vector Machine

又称Large Margin Classifer大间隔分类器

基本逻辑就是 既要找到一条分割线能使样本点分隔开，又要找到两个边界分界面的距离最远。

对于一些线性可分的数据集来说，可以找到这样一个合适的分割线，但是对于线性不可分的数据集来说，我们只有将一些混乱的样本实为错误的样本，才能找到合适的分割线，保证较大的准确性，我们称这样的为Soft-Margin SVM。

不过说到底，SVM还是一个线性分类器，对于一些非线性的数据集，无法用这个方法区分， 这就引入了Kernel，我们可以引用更高维度来将低维中线性不可分变成高维中线性可分。

Hyperplane：超平面  Kernel：核函数

## EfficientNet代码部分

```python
# main.py
import argparse
parser = argparse.ArgumentParser(description='The First Line')
parser.add_argument('data', metavar='DIR', help='path to dataset')
parser.add_argument('-a','--arch',metavar='ARCH',default='resnet18',help='model architecture (default: resnet18)')
```

```shell
>>> python main.py -h
usage: main.py [-h] [-a ARCH] [-j N] 
The First Line

positional arguments:
  DIR                   path to dataset

optional arguments:
  -h, --help            show this help message and exit
  -a ARCH, --arch ARCH  model architecture (default: resnet18)

```

总的来说，`argparse`这个包可以让我们在输入命令的时候增加一些参数，来自定义运行。

argprase.ArgumentParser还有一个parse_args()方法