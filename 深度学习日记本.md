# 深度学习00

[toc]



[Typora正确食用方法](https://www.cnblogs.com/luckforefforts/p/13642696.html)

## 正则化

正则化 和 正则表达式 没有任何联系！！！

正则化：用各种方法去规范模型参数的方法。DropOut也是一种正则化。

花书中对正则化的定义：凡是可以减少泛化误差 而不是减少训练误差的方法，都可以称作正则化方法。（简单来说：凡是能减少过拟合的方法都是正则化方法）

L2范数：欧式距离，图像是一个圆

L1范数：曼哈顿距离，图像是一个旋转45°的正方形

注意：在两组计算中，即使得到的损失函数的值一样，但是w和b的取值很可能不相同，主要取决于w和b的初始值设置。所以为了不让这两个参数太大，我们就需要 把这两个参数的取值范围放到一个框框里。

## SVM支持向量机Support Vector Machine

又称Large Margin Classifer大间隔分类器

基本逻辑就是 既要找到一条分割线能使样本点分隔开，又要找到两个边界分界面的距离最远。

对于一些线性可分的数据集来说，可以找到这样一个合适的分割线，但是对于线性不可分的数据集来说，我们只有将一些混乱的样本实为错误的样本，才能找到合适的分割线，保证较大的准确性，我们称这样的为Soft-Margin SVM。

不过说到底，SVM还是一个线性分类器，对于一些非线性的数据集，无法用这个方法区分， 这就引入了Kernel，我们可以引用更高维度来将低维中线性不可分变成高维中线性可分。

Hyperplane：超平面  Kernel：核函数

## EfficientNet代码部分

```python
# main.py
import argparse
parser = argparse.ArgumentParser(description='The First Line')
parser.add_argument('data', metavar='DIR', help='path to dataset')
parser.add_argument('-a','--arch',metavar='ARCH',default='resnet18',help='model architecture (default: resnet18)')
```

```shell
>>> python main.py -h
usage: main.py [-h] [-a ARCH] [-j N] 
The First Line

positional arguments:
  DIR                   path to dataset

optional arguments:
  -h, --help            show this help message and exit
  -a ARCH, --arch ARCH  model architecture (default: resnet18)

```

总的来说，`argparse`这个包可以让我们在输入命令的时候增加一些参数，来自定义运行。

argprase.ArgumentParser还有一个parse_args()方法

## 	获取argparse定义的参数

```python
import argparse
parse = argparse.ArgumentParser(description='The Firse Line')
parse.add_argument('data', metavar='DIR', help='path to dataset')

args = parse.parse_args()
print(args.data)
```

参数解读：

- [ ] action：命令行遇到参数时的动作，默认值是store
  当action=sotre_true时，有值传入就为True，无值传入就是False
- [ ] default：不指定参数时的默认值
- [ ] type：命令行参数应该被转换成的类型
- [ ] metavar：在usage说明中的参数名称，对于必选参数默认就是参数名称，对于可选参数默认是全大写的参数名称。用来控制部分命令行参数的显示，只是影响参数的显示信息，不影响代码内部获取命令行参数的对象。
- [ ] dest：解析后的参数名称

## random.seed()

seed()方法改变随机数生成器的种子，可以在调用其他随机模块函数之前调用此函数。

参数可有可无，当没参数的时候，每次生成的随机种子不一样。
当有参数且参数相等的时候，生成的随机种子相同。
有参但不相等，生成的种子不同。

```python
import random
# 随机数不一样
random.seed()
print('随机数1：',random.random())
random.seed()
print('随机数2：',random.random())

# 随机数一样
random.seed(1)
print('随机数3：',random.random())
random.seed(1)
print('随机数4：',random.random())
random.seed(2)
print('随机数5：',random.random())

'''
随机数1： 0.7643602170615428
随机数2： 0.31630323818329664
随机数3： 0.13436424411240122
随机数4： 0.13436424411240122
随机数5： 0.9560342718892494
'''
```

## torch.manual_seed(int seed)

在需要生成随机数的实验中，确保每次运行.py文件时，生成的随机数都是固定的，这样每次实验结果显示也就一致了。

```python
torch.manual_seed(1)
torch.rand(1,2)
# 无论执行多少次，输出的结果是一样的。
# 如果不用第一行，那每次结果就不同的。
```

## cuda的随机种子

`torch.backends.cudnn.deterministic = True`

这个是设置cuda的随机种子，为了确保每次的训练结果相同，需要将这个flag设置为True，每次的卷积算法是确定的，即默认算法，配合上torch的随机种子，应该可以保证每次运行网络的时候相同输入的输出是固定的。

## os.environ["WORLD_SIZE"]

[知乎](https://zhuanlan.zhihu.com/p/360405558)

`os.environ.keys()`用来获取当前系统下的映像对象。

`num_gpus = int(os.environ["WORLD_SIZE"])` 用来获取当前主机的进程数量，为后面多GPU同时处理数据做准备。

"WORLD_SIZE"是由torch.distributed.launch.py产生

## torch.cuda.device_count()

返回当前主机可用GPU的数量。

## torch.multiprocessing.spawn()

如果其中一个进程以非零退出状态退出，则会杀死其余进程，并引发异常，导致终止。

```
torch.multiprocessing.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))
#main_worker 函数
# nproce 派生的进程数量
# args 传递给函数的参数
```

- **进程组的[相关概念](https://link.zhihu.com/?target=https%3A//github.com/pytorch/examples/blob/master/distributed/ddp/README.md)**

- - **GROUP**：进程组，大部分情况下DDP的各个进程是在同一个进程组下
  - **WORLD_SIZE**：总的进程数量 (原则上一个process占用一个GPU是较优的)
  - **RANK**：当前进程的序号，用于进程间通讯，rank = 0 的主机为 master 节点
  - **LOCAL_RANK**：当前进程对应的GPU号

## torch.distributed.init_process_group

初始化进程组

## 标准=损失函数；优化器=随机梯度下降函数

## checkpoint

什么是checkpoint？这是一种为长时间运行进程准备的容错技术。

在系统故障的时候 拍摄系统快照的方法，一旦出问题不会让进度全部丢失，可以在出问题的地方作为重新运行的起点。

训练深度学习的模型时，checkpoint是模型的权重，可以用来做预测，或作为持续训练的基础。

## os.path()

[菜鸟教程](https://www.runoob.com/python3/python3-os-path.html)

主要用来获取文件的属性

os.path.join(path1,path2) 把目录和文件名合成一个路径。

## advprop

[Adversarial Examples Improve Image Recognition](https://blog.csdn.net/saturdaysunset/article/details/108186808)

采用对抗样本去提升图像识别能力，对抗样本是一种在普通样本数据上加一些噪声信号得到的新数据，这样的样本人类看起来没有什么区别，但是在机器上却是致命的，会使原本识别率很好的网络错误率大大提升。

针对这种情况，作者在论文中提出了一种叫做辅助BN的方法，思想很简单，就是在原本网络里batch norm层（主BN）旁边加了一条旁路，也是batch norm层，因为是要用来给对抗样本进行训练，为了和原本的BN做区分，所以叫做辅助BN。

## PIL图像 Python Imaging Library

python中的一个库函数，用来对图像做处理的，可以裁剪、滤镜、模糊等功能。

***

---

注释内容

## torchvision.transforms

[torchvision.transforms的图像预处理](https://blog.csdn.net/m0_37163827/article/details/111284328)

- [ ] <kbd>Compose()</kbd> 参数是对transform所有图像进行操作，会将transforms列表遍历一次。

  ```python
  transforms.Compose([
       transforms.CenterCrop(10),
       transforms.ToTensor(),
   ])
  ```

- [ ] <kbd>Lambda</kbd> 对图片进行处理，有时候我们不想检测图片的全部，只想检测部分，就通过一个匿名函数对图片进行处理。
- [ ] <kbd>Normalize(mean,std)</kbd> 对图片用均值和标准差归一化一张向量图像
  第一个参数mean：均值
  第二个参数std：标准差
- [ ] <kbd>ToTensor()</kbd> 将PIL图片或者numpy.ndarray转成tensor，注意形状顺序和通道顺序是有区别的，ToTensor是做归一化且改变了形状顺序。
- [ ] <kbd>RandomResizedCrop()</kbd> 缩放后随机裁剪，参数size指定了裁剪的大小。
- [ ] <kbd>RandomHorizontalFlip()</kbd> 以概率p水平翻转给定的图像。默认0.5

## torchvision.datasets

- [ ] <kbd>ImageFolder()</kbd> 是一个通用的数据加载器，对数据集的训练，验证或者测试。
  参数1：root 图片存储的根目录
  参数2：transform 对图片进行预处理的操作，这里可以用transforms.Compose()对每一张图片做一组连续的操作
  参数3：target_transform 对图片类别进行预处理的操作

## torch.utils.data.DataLoader()

除了dataset是必选的，其余都是可选的参数。

1. dataset：需要训练的数据集
2. batch_size：每批要加载多少个数据样本
3. shuffle：为True每次epoch都重新打乱样本
4. sampler：定义了怎么从数据集中取样本，如果指定了方法，那么shuffle一定不能为True。
5. num_workers：加载数据需要多少个子进程。
6. pin_memory：True固定内存大小。

## hyperparameter

超参 hyperparameter：模型的层数以及每层的大小

模型参数：权重

## 验证集上的评估模型

为什么需要评估模型？评估模型的重点是将数据划分为三个集合：训练集、验证集和测试集。在训练数据上训练模型，在验证数据上评估模型。一旦找到了最佳参数，就在测试数据上最后测试一次。

[评估模型的几种方法](https://blog.csdn.net/qq_36178899/article/details/84986563)

## 参数的*和**

`*args`表示将参数作为一个元组使用

`**args`表示将参数作为一个字典使用

## with torch.no_grad():

被`with torch.no_grad()` 包裹的代码不会进行梯度计算。

## polling的介绍

[知乎文章](https://www.zhihu.com/question/303215483/answer/615115629) 

## python操作excel

[知乎文章](https://zhuanlan.zhihu.com/p/259583430)

## python操作文件等

[博客园](https://www.cnblogs.com/sui776265233/p/10843641.html)

## 如何使用EfficientNet训练自己的数据集

[参考1](https://blog.csdn.net/weixin_40520963/article/details/105733117)    [github代码分享](https://github.com/Levigty/EfficientNet-Pytorch)

[参考2](https://blog.csdn.net/qq_41672428/article/details/112529933)

# 使用b0训练花卉样本集结果

<img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211003200939041.png" alt="image-20211003200939041" style="zoom:50%;" /><img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211003201021770.png" alt="image-20211003201021770" style="zoom:50%;" />

## 使用b0训练鱼样本集结果

第一遍：<img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211005152533132.png" alt="image-20211005152533132" style="zoom:80%;" />

怀疑是不是要求的准确率太高了(>0.999)，现在修改为 大于0.7就结束循环

第二遍：<img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211005152953106.png" alt="image-20211005152953106" style="zoom:80%;" />

仍然是这个错误。现在又回到花卉集的样本还是这个错误，

在网上搜了一下，发现是需要把test_model方法改为tst_model就可以了，来试一试：艹，果然可以了。难道以后的方法名不能含有test了吗？

回到鱼类数据集，看一下测试结果：<img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211005154220561.png" alt="image-20211005154220561" style="zoom:50%;" />修改精确度到0.9试一下。<img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211005154544305.png" alt="image-20211005154544305" style="zoom:50%;" />可以，4次循环（54s）就可以到达94%的准确率了！

现在我们把学习率调整到0.02，并且精确度调到0.99看一下结果怎么样：

<img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211005155435908.png" alt="image-20211005155435908" style="zoom:80%;" />第九轮（2m 3s）到99.4%的准确率，很不错！

现在更换一个模型，使用B1-B7模型试一下。

B0：<img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211005165401190.png" alt="image-20211005165401190" style="zoom:80%;" />

B1：<img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211005173914881.png" alt="image-20211005173914881" style="zoom:80%;" />

B1的训练过程很曲折，首先出现了显卡内存不够用的问题，方法是修改了几个efficientnet/model.py和utils.py文件中的几处代码，加上`with torch.no_grad():` 之后，能正常运行不报错，（也不知道这对代码的正确性有没有影响）。从训练过程来看，直到训练次数拉满到60次，训练集的准确率仍然没有达到设置的0.99 ，并且就想在折线图中展示的那样，会出现波动的现象，在0.95-0.97之间。下面试一下B2的效果，这次把精度设置在0.95看看结果会不会不同。（by the way 越往后面的模型越大，B1--30M，B2--35M）

B2：<img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211005183457219.png" alt="image-20211005183457219" style="zoom:80%;" />

B2模型效果和B1相差无几，直到第48轮准确度才到95.24% , 勉强到设置的0.95, 用时9m 56s ，速度也是相当慢了。我怀疑是不是设置了`with torch.no_grad():` 之后出了问题，现在再来试一下B0，看看效果怎么样。

果然是这里出了问题！！！现在B0执行的速度也是相当慢了，看来得把代码再改回来了。

又修改回来的B0 在1m 5s的时间内进行了5次批训练，准确度就到达了96.6%，我感觉一切都回来了！！！

但是其他模型怎么办呢，运行应该又会出现没有内存空间的问题，果然还是来了。

刚才问了可鑫，他告诉我把batchsize减小就行了，我把batchsize从64变到32，奇迹发生了，B1模型直接在3次迭代后就到达了96.07%运行时间43s！！！

<img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211005203550267.png" alt="image-20211005203550267" style="zoom:80%;" />

可鑫太强了！！！以后多请教了

batchsize为32的B2：4次迭代 97.2%  用时51s <img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211005204219449.png" alt="image-20211005204219449" style="zoom:80%;" />

batchsize为32的B3：4次迭代97.51%  用时57s<img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211005204557925.png" alt="image-20211005204557925" style="zoom:80%;" />

后面的就不运行了，应该在这中小型数据集上效果肯定不错。

换个大的数据集试一试。



## Numpy基础知识

numpy是python中科学计算的核心库，提供了一个高表现、高位矩阵计算工具。

### 数组：

```python
a = np.array([1, 2, 3]) #创建一个一维数组
print(type(a)) #<class	'numpy.ndarray'>
print(a.dtype) #int64
print(a.shape) #(3,)
```

可以通过下标来访问或者修改数组中的元素。

```python
b = a[:2, 1:3] #数组a的前两行 其中的1,2列
```

### 基本函数

sum

```python
x = np.array([[1, 2], [3, 4]])
print(np.sum(x)) #10
print(np.sum(x, axis=0)) #[4 6] 按列求和
print(np.sum(x, axis=1)) #[3 7] 按行求和
```

## Pytorch基础知识

pytorch是一个拥有强力GPU加速的张量和动态构建网络的库，主要构件是张量，所有可以把PyTorch当做Numpy来用，好多操作都是类似的，但是要比Numpy快很多倍。

### numpy--tensor互相转换

```python
import torch
import numpy as np
# 创建一个 numpy ndarray
numpy_tensor = np.random.randn(10, 20)
#可以通过两种方式将numpy的ndarray转换为tensor上
pytorch_tensor1 = torch.Tensor(numpy_tensor)
pytorch_tensor2 = torch.from_numpy(numpy_tensor)
# 同时也可以使用方法将tensor转化为ndarray
# 1.如果tensor在CPU上，可以直接转换
numpy_array = pytorch_tensor1.numpy()
# 2.如果tensor在GPU上，需要经过CPU才能转换
numpy_array = pytorch_tensor2.cpu().numpy()
```

### tensor使用GPU加速

```python
# 第一种方式：定义cuda数据类型
dtype = torch.cuda.FloatTensor #定义默认GPU的数据类型
gpu_tensor = torch.randn(10, 20).type(dtype)
# 第二种方式：推荐使用
gpu_tensor = torch.randn(10, 20).cuda(0) #放到第一个GPU上
```

```python
# 有两种方式访问到tensor的大小
print(pytorch_tensor.shpae) #torch.Size([10, 20])
print(pytorch_tensor.size())
# 得到tensor的数据类型
print(pytorch_tensor.type()) #torch.FloatTensor
# 得到tensor的维度
print(pytorch_tensor.dim()) # 2
# 得到tensor的所有元素的个数
print(pytorch_tensor.numel()) #200
```

### tensor的操作

```python
x = torch.ones(2, 2) #得到一个大小是2*2的全1tensor
print(x.type()) #torch.FloatTensor
# 将浮点型转换为整型
x = x.long()
x = x.float()

# 创建一个tensor
x = torch.randn(4, 3)
# 取每行的最大值
max_value, max_index = torch.max(x, dim=1)
# 取每列的最大值
max_value, max_index = torch.max(x, dim=0)
# 对每一行求和
sum_x = torch.sum(x, dim=1)
```

```python
# 对tensor增加或者减少维度
x = x.unsqueeze(0) #在第一维增加 [4,3]-->[1,4,3]
x = x.unsqueeze(1) #在第二维增加 [1,4,3]-->[1,1,4,3]
x = x.squeeze(0) #第一维减少 [1,1,4,3]-->[1,4,3]
x = x.squeeze() #不指定参数 删去第一维

# 使用permute和transpose进行维度交换
x = torch.randn(3,4,5)
x = x.permute(1,0,2) #[3,4,5]-->[4,3,5]
x = x.transpose(0,2) #[4,3,5]-->[5,3,4]
```

```python
# 使用view对tensor进行reshape
x = x.view(-1,5) #-1表示任意大小，5表示第二维变成5
# [3,4,5]-->[12,5]
x = x.view(3,20) #[12,5]-->[3,20]
```

### tensor的inplace操作

即操作的对象是自己，可以不用复制给其他变量,不需要另外开辟内存空间，方法很简单，一般是在操作的符号后面加上`_`,

```python
x = torch.ones(3,3)
y = torch.randn(3,3)
x.unsqueeze_(0)
x.transpose_(1,0)
x.add_(y) #将x和y相加的结果直接赋值给x
print(x)
```

## Variable

能够计算图的tensor，Variable是对tensor的封装，操作和tensor是一样的。
但是每个Variable都有三个属性，

1. Variable中的tensor本身`.data`
2. 对应tensor的梯度`.grad`
3. 以及这个Variable是通过什么方式得到的`.grad_fn`

```python
# 导入Variable
from torch.autograd import Variable
x_tensor = torch.randn(10,5)
y_tensor = torch.randn(10,5)
# 将tensor变成Variable
x = Variable(x_tensor, requires_grad=True) #默认不需要求梯度，所以这里需要设置这个参数
y = Variable(y_tensor, requires_grad=True)
# 对这两个tensor求和
z = torch.sum(x + y)
print(z.data) # -2.1379[torch.FloatTensor of size 1]
print(z.grad_fn) #<SumBackward0	object	at 0x10da636a0>
# 求x和y的梯度
z.backward()
print(x.grad)
print(y.grad)
```

## PyTorch的自动求导

自动求导是pytorch中非常重要的特性，减少了模型构建的时间。

### 简单情况的自动求导

```python
x = Varibale(torch.Tensor([2]), requires_grad=True)
y = x+2
z = y**2 + 3
print(z) # 19

z.backward() #对当前函数计算梯度
print(x.grad()) # 8
```

### 复杂情况的自动求导

```python
m = Variable(torch.FloatTensor([[2,3]]),requires_grad=True)# 构建一个1*2的矩阵
n = Variable(torch.zeros(1,2))
# 通过m中的值计算新的n中的值
n[0,0] = m[0,0] ** 2
n[0,1] = n[0,1] ** 3
# 计算之后的n=4,27
```

在pytorch中，如果要调用自动求导，需要往`backward()`中传入一个参数，这个参数的形状和n一样大。

```python
n.backward(torch.ones_like(n)) #将(w0,w1)取成(1,1)
print(m.grad) # 4, 27
```

多次求导需要在第一的backward中增加参数`retain_graph=True`,下一次求导结果会和第一次求导结果相加输出。
