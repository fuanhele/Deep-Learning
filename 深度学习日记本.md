# 深度学习00

[toc]



[Typora正确食用方法](https://www.cnblogs.com/luckforefforts/p/13642696.html)

## 正则化

正则化 和 正则表达式 没有任何联系！！！

正则化：用各种方法去规范模型参数的方法。DropOut也是一种正则化。

花书中对正则化的定义：凡是可以减少泛化误差 而不是减少训练误差的方法，都可以称作正则化方法。（简单来说：凡是能减少过拟合的方法都是正则化方法）

L2范数：欧式距离，图像是一个圆

L1范数：曼哈顿距离，图像是一个旋转45°的正方形

注意：在两组计算中，即使得到的损失函数的值一样，但是w和b的取值很可能不相同，主要取决于w和b的初始值设置。所以为了不让这两个参数太大，我们就需要 把这两个参数的取值范围放到一个框框里。

## SVM支持向量机Support Vector Machine

又称Large Margin Classifer大间隔分类器

基本逻辑就是 既要找到一条分割线能使样本点分隔开，又要找到两个边界分界面的距离最远。

对于一些线性可分的数据集来说，可以找到这样一个合适的分割线，但是对于线性不可分的数据集来说，我们只有将一些混乱的样本实为错误的样本，才能找到合适的分割线，保证较大的准确性，我们称这样的为Soft-Margin SVM。

不过说到底，SVM还是一个线性分类器，对于一些非线性的数据集，无法用这个方法区分， 这就引入了Kernel，我们可以引用更高维度来将低维中线性不可分变成高维中线性可分。

Hyperplane：超平面  Kernel：核函数

## EfficientNet代码部分

```python
# main.py
import argparse
parser = argparse.ArgumentParser(description='The First Line')
parser.add_argument('data', metavar='DIR', help='path to dataset')
parser.add_argument('-a','--arch',metavar='ARCH',default='resnet18',help='model architecture (default: resnet18)')
```

```shell
>>> python main.py -h
usage: main.py [-h] [-a ARCH] [-j N] 
The First Line

positional arguments:
  DIR                   path to dataset

optional arguments:
  -h, --help            show this help message and exit
  -a ARCH, --arch ARCH  model architecture (default: resnet18)

```

总的来说，`argparse`这个包可以让我们在输入命令的时候增加一些参数，来自定义运行。

argprase.ArgumentParser还有一个parse_args()方法

## 	获取argparse定义的参数

```python
import argparse
parse = argparse.ArgumentParser(description='The Firse Line')
parse.add_argument('data', metavar='DIR', help='path to dataset')

args = parse.parse_args()
print(args.data)
```

参数解读：

- [ ] action：命令行遇到参数时的动作，默认值是store
  当action=sotre_true时，有值传入就为True，无值传入就是False
- [ ] default：不指定参数时的默认值
- [ ] type：命令行参数应该被转换成的类型
- [ ] metavar：在usage说明中的参数名称，对于必选参数默认就是参数名称，对于可选参数默认是全大写的参数名称。用来控制部分命令行参数的显示，只是影响参数的显示信息，不影响代码内部获取命令行参数的对象。
- [ ] dest：解析后的参数名称

## random.seed()

seed()方法改变随机数生成器的种子，可以在调用其他随机模块函数之前调用此函数。

参数可有可无，当没参数的时候，每次生成的随机种子不一样。
当有参数且参数相等的时候，生成的随机种子相同。
有参但不相等，生成的种子不同。

```python
import random
# 随机数不一样
random.seed()
print('随机数1：',random.random())
random.seed()
print('随机数2：',random.random())

# 随机数一样
random.seed(1)
print('随机数3：',random.random())
random.seed(1)
print('随机数4：',random.random())
random.seed(2)
print('随机数5：',random.random())

'''
随机数1： 0.7643602170615428
随机数2： 0.31630323818329664
随机数3： 0.13436424411240122
随机数4： 0.13436424411240122
随机数5： 0.9560342718892494
'''
```

## torch.manual_seed(int seed)

在需要生成随机数的实验中，确保每次运行.py文件时，生成的随机数都是固定的，这样每次实验结果显示也就一致了。

```python
torch.manual_seed(1)
torch.rand(1,2)
# 无论执行多少次，输出的结果是一样的。
# 如果不用第一行，那每次结果就不同的。
```

## cuda的随机种子

`torch.backends.cudnn.deterministic = True`

这个是设置cuda的随机种子，为了确保每次的训练结果相同，需要将这个flag设置为True，每次的卷积算法是确定的，即默认算法，配合上torch的随机种子，应该可以保证每次运行网络的时候相同输入的输出是固定的。

## os.environ["WORLD_SIZE"]

[知乎](https://zhuanlan.zhihu.com/p/360405558)

`os.environ.keys()`用来获取当前系统下的映像对象。

`num_gpus = int(os.environ["WORLD_SIZE"])` 用来获取当前主机的进程数量，为后面多GPU同时处理数据做准备。

"WORLD_SIZE"是由torch.distributed.launch.py产生

## torch.cuda.device_count()

返回当前主机可用GPU的数量。

## torch.multiprocessing.spawn()

如果其中一个进程以非零退出状态退出，则会杀死其余进程，并引发异常，导致终止。

```
torch.multiprocessing.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))
#main_worker 函数
# nproce 派生的进程数量
# args 传递给函数的参数
```

- **进程组的[相关概念](https://link.zhihu.com/?target=https%3A//github.com/pytorch/examples/blob/master/distributed/ddp/README.md)**

- - **GROUP**：进程组，大部分情况下DDP的各个进程是在同一个进程组下
  - **WORLD_SIZE**：总的进程数量 (原则上一个process占用一个GPU是较优的)
  - **RANK**：当前进程的序号，用于进程间通讯，rank = 0 的主机为 master 节点
  - **LOCAL_RANK**：当前进程对应的GPU号

## torch.distributed.init_process_group

初始化进程组

## 标准=损失函数；优化器=随机梯度下降函数

## checkpoint

什么是checkpoint？这是一种为长时间运行进程准备的容错技术。

在系统故障的时候 拍摄系统快照的方法，一旦出问题不会让进度全部丢失，可以在出问题的地方作为重新运行的起点。

训练深度学习的模型时，checkpoint是模型的权重，可以用来做预测，或作为持续训练的基础。

## os.path()

[菜鸟教程](https://www.runoob.com/python3/python3-os-path.html)

主要用来获取文件的属性

os.path.join(path1,path2) 把目录和文件名合成一个路径。

## advprop

[Adversarial Examples Improve Image Recognition](https://blog.csdn.net/saturdaysunset/article/details/108186808)

采用对抗样本去提升图像识别能力，对抗样本是一种在普通样本数据上加一些噪声信号得到的新数据，这样的样本人类看起来没有什么区别，但是在机器上却是致命的，会使原本识别率很好的网络错误率大大提升。

针对这种情况，作者在论文中提出了一种叫做辅助BN的方法，思想很简单，就是在原本网络里batch norm层（主BN）旁边加了一条旁路，也是batch norm层，因为是要用来给对抗样本进行训练，为了和原本的BN做区分，所以叫做辅助BN。

## PIL图像 Python Imaging Library

python中的一个库函数，用来对图像做处理的，可以裁剪、滤镜、模糊等功能。

***

---

注释内容

## torchvision.transforms

[torchvision.transforms的图像预处理](https://blog.csdn.net/m0_37163827/article/details/111284328)

- [ ] <kbd>Compose()</kbd> 参数是对transform所有图像进行操作，会将transforms列表遍历一次。

  ```python
  transforms.Compose([
       transforms.CenterCrop(10),
       transforms.ToTensor(),
   ])
  ```

- [ ] <kbd>Lambda</kbd> 对图片进行处理，有时候我们不想检测图片的全部，只想检测部分，就通过一个匿名函数对图片进行处理。
- [ ] <kbd>Normalize(mean,std)</kbd> 对图片用均值和标准差归一化一张向量图像
  第一个参数mean：均值
  第二个参数std：标准差
- [ ] <kbd>ToTensor()</kbd> 将PIL图片或者numpy.ndarray转成tensor，注意形状顺序和通道顺序是有区别的，ToTensor是做归一化且改变了形状顺序。
- [ ] <kbd>RandomResizedCrop()</kbd> 缩放后随机裁剪，参数size指定了裁剪的大小。
- [ ] <kbd>RandomHorizontalFlip()</kbd> 以概率p水平翻转给定的图像。默认0.5

## torchvision.datasets

- [ ] <kbd>ImageFolder()</kbd> 是一个通用的数据加载器，对数据集的训练，验证或者测试。
  参数1：root 图片存储的根目录
  参数2：transform 对图片进行预处理的操作，这里可以用transforms.Compose()对每一张图片做一组连续的操作
  参数3：target_transform 对图片类别进行预处理的操作

## torch.utils.data.DataLoader()

除了dataset是必选的，其余都是可选的参数。

1. dataset：需要训练的数据集
2. batch_size：每批要加载多少个数据样本
3. shuffle：为True每次epoch都重新打乱样本
4. sampler：定义了怎么从数据集中取样本，如果指定了方法，那么shuffle一定不能为True。
5. num_workers：加载数据需要多少个子进程。
6. pin_memory：True固定内存大小。

## hyperparameter

超参 hyperparameter：模型的层数以及每层的大小

模型参数：权重

## 验证集上的评估模型

为什么需要评估模型？评估模型的重点是将数据划分为三个集合：训练集、验证集和测试集。在训练数据上训练模型，在验证数据上评估模型。一旦找到了最佳参数，就在测试数据上最后测试一次。

[评估模型的几种方法](https://blog.csdn.net/qq_36178899/article/details/84986563)

## 参数的*和**

`*args`表示将参数作为一个元组使用

`**args`表示将参数作为一个字典使用

## with torch.no_grad():

被`with torch.no_grad()` 包裹的代码不会进行梯度计算。

## 如何使用EfficientNet训练自己的数据集

[参考1](https://blog.csdn.net/weixin_40520963/article/details/105733117)    [github代码分享](https://github.com/Levigty/EfficientNet-Pytorch)

[参考2](https://blog.csdn.net/qq_41672428/article/details/112529933)

# 使用b0训练花卉样本集结果

<img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211003200939041.png" alt="image-20211003200939041" style="zoom:50%;" /><img src="C:\Users\LLY\AppData\Roaming\Typora\typora-user-images\image-20211003201021770.png" alt="image-20211003201021770" style="zoom:50%;" />

